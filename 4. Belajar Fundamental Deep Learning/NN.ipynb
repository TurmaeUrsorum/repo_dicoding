{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d9d9344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 16:08:56.656768: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import polars as pl\n",
    "import modin.pandas as mpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0542e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', 'clang 18'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.sysconfig.get_build_info())\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa76166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayam/miniconda3/envs/tf220/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758617458.481131    5101 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2286 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-23 15:50:59.389342: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2025-09-23 15:50:59.518265: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2025-09-23 15:51:00.232373: I external/local_xla/xla/service/service.cc:163] XLA service 0x75602800a7f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-09-23 15:51:00.232399: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2025-09-23 15:51:00.247123: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-09-23 15:51:00.324082: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
      "2025-09-23 15:51:00.343380: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-09-23 15:51:00.688278: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_96', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-09-23 15:51:01.023671: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_96', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-09-23 15:51:01.885003: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 28 bytes spill stores, 28 bytes spill loads\n",
      "\n",
      "2025-09-23 15:51:02.085563: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_226', 248 bytes spill stores, 248 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 103/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1763"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758617463.025382    5326 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.8308 - loss: 0.4734\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.3585\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8809 - loss: 0.3215\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8869 - loss: 0.3002\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8967 - loss: 0.2783\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.2628\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9065 - loss: 0.2519\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2429\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2292\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x756164461d90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    " \n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    " \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "                              loss = \"sparse_categorical_crossentropy\",\n",
    "                              metrics = [\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acff5535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55296f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Built with GPU support: True\n",
      "WARNING:tensorflow:From /tmp/ipykernel_6997/1848223583.py:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758618088.619544    6997 gpu_device.cc:2020] Created device /device:GPU:0 with 2286 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Cek daftar GPU yang terdeteksi\n",
    "print(\"GPUs detected:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Cek apakah TensorFlow bisa pakai GPU\n",
    "print(\"Built with GPU support:\", tf.test.is_built_with_cuda())\n",
    "print(\"GPU available:\", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146167a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15273892133724604692\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2397175808\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11219111035386157091\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758618096.109964    6997 gpu_device.cc:2020] Created device /device:GPU:0 with 2286 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59209d0",
   "metadata": {},
   "source": [
    "# Pra-pemrosesan Data untuk Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf3eb0",
   "metadata": {},
   "source": [
    "## Data Augmentasi dengan TensorFlow <= 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd1a3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini untuk versi lama, versi baru sudah menggunakan pre prorses langsud di model nya\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "train_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255,\n",
    "                    rotation_range=20,\n",
    "                    horizontal_flip=True,\n",
    "                    shear_range = 0.2,\n",
    "                    fill_mode = 'nearest')\n",
    " \n",
    "test_datagen = ImageDataGenerator(\n",
    "                    rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be170b6",
   "metadata": {},
   "source": [
    "## Data Augmentasi dengan TensorFlow > 2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05db4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "IMG_SIZE = 180\n",
    " \n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  layers.Rescaling(1./255)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fa77bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758618106.385344    6997 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2286 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ea2f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  # Menambahkan processing image yang telah didefinisikan sebelumnya\n",
    "  resize_and_rescale,\n",
    "  data_augmentation,\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  # Sesuaikan sisa layer dengan kasus yang Anda miliki\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376d8934",
   "metadata": {},
   "source": [
    "Pada tahap terakhir, Anda perlu memasukkan data augmentasi tersebut pada layer sequentials ketika membangun struktur neural network agar seluruh dataset yang ada dapat diproses dan melakukan pelatihan dengan baik. Berikut contoh kode yang dapat Anda lakukan untuk menerapkan data augmentasi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea707a9",
   "metadata": {},
   "source": [
    "## Pemrosesan Data Bahasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8341c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'love': 2, 'my': 3, 'cat': 4}\n",
      "[[1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences = [\"I love my cat\"]\n",
    " \n",
    "tokenizer = Tokenizer(num_words = 100)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    " \n",
    "print(tokenizer.word_index)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a2db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer:  {'<OOV>': 1, 'my': 2, 'cat': 3, 'i': 4, 'love': 5, 'do': 6, 'you': 7, 'think': 8, 'is': 9, 'cute': 10}\n",
      "Sequences:  [[4, 5, 2, 3], [6, 7, 8, 2, 3, 9, 10], [1, 3, 1, 7]]\n",
      "Padded:  [[ 4  5  2  3  0  0  0  0  0  0]\n",
      " [ 6  7  8  2  3  9 10  0  0  0]\n",
      " [ 1  3  1  7  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sentences = [\"I love my cat\",\n",
    "             \"Do you think my cat is cute?\"]\n",
    " \n",
    " \n",
    "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sentences = [\"I love my cat\",\n",
    "             \"Do you think my cat is cute?\",\n",
    "             \"Additional cat for you\"]\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    " \n",
    "padded = pad_sequences(sequences, padding=\"post\", truncating=\"post\", maxlen=10)\n",
    " \n",
    "print(\"Tokenizer: \",tokenizer.word_index)\n",
    "print(\"Sequences: \",sequences)\n",
    "print(\"Padded: \",padded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
